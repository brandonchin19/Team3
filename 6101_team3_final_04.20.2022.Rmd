---
title: "DATS 6101 Final Project"
author: "Brandon Chin, Paul Kelly, Ksenia Shadrina, Luke Wu"
date: "4/11/22"
# date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
library(tidyverse)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
#options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

```{r modify_outlierKD2}
#' Original outlierKD function by By Klodian Dhana,
#' https://www.r-bloggers.com/identify-describe-plot-and-remove-the-outliers-from-the-dataset/
#' Modified to have third argument for removing outliers instead of interactive prompt,
#' and after removing outlier, original df will not be changed. The function returns the a df,
#' which can be saved as original df name if desired.
#' Also added QQ-plot in the output, with options to show/hide boxplot, histogram, qqplot.
#' Check outliers, and option to remove them, save as a new dataframe.
#' @param df The dataframe.
#' @param var The variable in the dataframe to be checked for outliers
#' @param rm Boolean. Whether to remove outliers or not.
#' @param boxplt Boolean. Whether to show the boxplot, before and after outliers removed.
#' @param histogram Boolean. Whether to show the histogram, before and after outliers removed.
#' @param qqplt Boolean. Whether to show the qqplot, before and after outliers removed.
#' @return The dataframe with outliers replaced by NA if rm==TRUE, or df if nothing changed
#' @examples
#'   outlierKD2(mydf, height, FALSE, TRUE, TRUE, TRUE)
#'   mydf = outlierKD2(mydf, height, TRUE, TRUE, TRUE, TRUE)
#'   mydfnew = outlierKD2(mydf, height, TRUE)
#' @export
outlierKD2 <- function(df, var, rm=TRUE, boxplt=TRUE, histogram=TRUE, qqplt=TRUE) {
  dt = df # duplicate the dataframe for potential alteration
  var_name <- eval(substitute(var),eval(dt))
  na1 <- sum(is.na(var_name))
  m1 <- mean(var_name, na.rm = T)
  colTotal <- boxplt+histogram+qqplt
  par(mfrow=c(2, max(2,colTotal)), oma=c(0,0,3,0)) # fixed issue with only 0 or 1 chart selected
  if (qqplt) {
    qqnorm(var_name, main = "With outliers")
    qqline(var_name)
  }
  if (histogram) { hist(var_name, main="With outliers", xlab=NA, ylab=NA) }
  if (boxplt) { boxplot(var_name, main="With outliers") }
  outlier <- boxplot.stats(var_name)$out
  mo <- mean(outlier)
  var_name <- ifelse(var_name %in% outlier, NA, var_name)
  if (qqplt) {
    qqnorm(var_name, main = "Without outliers")
    qqline(var_name)
  }
  if (histogram) { hist(var_name, main="Without outliers", xlab=NA, ylab=NA) }
  if (boxplt) { boxplot(var_name, main="Without outliers") }
  
  if(colTotal > 0) {  # if no charts are wanted, skip this section
    title("Outlier Check", outer=TRUE)
    na2 <- sum(is.na(var_name))
    cat("Outliers identified:", na2 - na1, "\n")
    cat("Propotion (%) of outliers:", round((na2 - na1) / sum(!is.na(var_name))*100, 1), "\n")
    cat("Mean of the outliers:", round(mo, 2), "\n")
    m2 <- mean(var_name, na.rm = T)
    cat("Mean without removing outliers:", round(m1, 2), "\n")
    cat("Mean if we remove outliers:", round(m2, 2), "\n")
  }
  # response <- readline(prompt="Do you want to remove outliers and to replace with NA? [yes/no]: ")
  # if(response == "y" | response == "yes"){
  if(rm){
      dt[as.character(substitute(var))] <- invisible(var_name)
      #assign(as.character(as.list(match.call())$dt), dt, envir = .GlobalEnv)
      cat("Outliers successfully removed", "\n")
      return(invisible(dt))
  } else {
      cat("Nothing changed", "\n")
      return(invisible(df))
  }
}
```

### Research Topic:

Our Github repository address is:https://github.com/brandonchin19/Team3/.

### Load in dataset that has been cleaned for appropriate variables, outliers, and Missing values

```{r, results='hide'}
loans <- data.frame(read.csv("loans.csv"))
str(loans) #24018 obs. of  9 variables # dropped applicant sex because it's essentially the same as derived sex
#View(loans) #if you want to take a look at the data
```

### Changing vector types

```{r}
loans$derived_ethnicity = factor(loans$derived_ethnicity)
loans$derived_race = factor(loans$derived_race)
loans$derived_sex = factor(loans$derived_sex)
#loans$action_taken = factor(loans$action_taken)
loans$loan_amount = as.numeric(loans$loan_amount)
loans$interest_rate = as.numeric(loans$interest_rate)
loans$property_value = as.numeric(loans$property_value)
loans$income = as.numeric(loans$income)
loans$applicant_age = factor(loans$applicant_age)
str(loans)
```

#Examine if there are  missing values 

```{r, include=TRUE}
missvalue <- is.na(loans)
summary(missvalue) # no missing values
```

##Run initial summary statistics: note different scales for income and interest rate

```{r, results='show'}
options(scipen=9, digits = 3) 
Numerical_var <- subset(loans,select=c(loan_amount, income, property_value, interest_rate))
library(kableExtra)
summary_t<-kbl(summary(Numerical_var))%>%
  kable_styling()
summary_t
#Note the income values are weird; never noticed they were probably standardized (divided by 1000)
```


### VI. Exploratory Data Analysis

#Exploring the categorical values first

```{r, include=TRUE}
library(ggplot2)
ggplot(loans, aes(x = factor(derived_sex), fill=derived_sex)) +
    geom_bar()+
  labs(title="Graph 1. Applicant sex distribution", x="Applicant Sex", y="Count")
ggplot(loans, aes(x = factor(applicant_age),fill=applicant_age)) +
    geom_bar()+
  labs(title="Graph 2. Applicant age distribution", x="Applicant Age", y="Count")
ggplot(loans, aes(x = factor(derived_ethnicity), fill=derived_ethnicity)) +geom_bar()+
  labs(title="Graph 3. Applicant ethnicity distribution", x="Applicant Ethnicity", y="Count")
ggplot(loans, aes(x = factor(action_taken), fill=action_taken)) +
    geom_bar()+
  labs(title="Graph 4. Action taken distribution", x="Action Taken", y="Count")
ggplot(loans, aes(x = factor(derived_race), fill=derived_race)) +
    geom_bar()+
  labs(title="Graph 5. Derived Race", x="Race of the Applicant", y= "Count")+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

```{r, include=TRUE}
ggplot(loans,aes(x=loan_amount))+
  geom_histogram(color="black", fill="steelblue")+
  labs(title=" Graph 6. Histogram of Loan Amount", x="Loan Amount in dollars", y="Frequency")
ggplot(loans,aes(x=interest_rate))+
  geom_histogram(color="black", fill="pink")+
  labs(title="Graph 8. Histogram of Interest Rate", x="Interest Rates", y="Frequency")
ggplot(loans,aes(x=income))+
  geom_histogram(color="black", fill="green")+
  labs(title="Graph 9. Histogram of Income", x="Income in dollars", y="Frequency")
ggplot(loans,aes(x=property_value))+
  geom_histogram(color="black", fill="lightblue")+
  labs(title="Graph 10. Histogram of Property Values", x="Property Values in dollars", y="Frequency")
```




#Balancing the dataset!

```{r}
hmda <- data.frame(loans)
hmda$approval<- ifelse(hmda$action_taken=="1", "Approved","Denied")
hmda$approval<- factor(hmda$approval)
str(hmda)
table(hmda$approval)
# Approved   Denied 
#    18542     5476 
```


Checking frequency of approval variable and derived_race variable

```{r}
with(hmda,
     {
       print(table(derived_race))
       print(table(approval))
     }
)
```
Creating DownSample of hmda dataset, 
the Approved far outnumber the Denied making this dataset severely unbalanced 
  #Approved: 18542     Denied: 5476
```{r}
Approved<- which(hmda$action_taken=="1")
Denied<- which(hmda$action_taken=="3")
length(Approved)
length(Denied)
#The technique
approved_downsample<-sample(Approved,length(Denied))
hmda_down<- hmda[c(approved_downsample, Denied),]
str(hmda_down)
#10952 obs. of  11 variables
#Balanced Graph: confirming that it's balanced now
# ggplot(hmda_down, aes(x = factor(action_taken), fill=action_taken)) +
#     geom_bar()+
#   labs(title=" Action taken distribution in the Balanced Dataset", x="Action Taken", y="Count")
```


###The CHI SQUARE TESTS on balanced dataset 
Conducting Chi-squared Test on the downsampled dataset (hmda_down)

P-Value for contable1 is lower than .05 therefore we reject the null hypothesis. action_taken and derived_race are not independent of each other

```{r}
contable1= table(hmda_down$derived_race, hmda_down$action_taken)
xkabledply(contable1, title="Contingency table for Loan Approval and Race")
chitest1 = chisq.test(contable1)
chitest1
```



```{r}
contable2= table(hmda_down$derived_ethnicity, hmda_down$action_taken)
xkabledply(contable2, title="Contingency table for Loan Approval and Ethnicity")
chitest2 = chisq.test(contable2)
chitest2
```



```{r}
contable3= table(hmda_down$derived_sex, hmda_down$action_taken)
xkabledply(contable3, title="Contingency table for Loan Approval and Gender")
chitest3 = chisq.test(contable3)
chitest3
```

```{r}
contable4= table(hmda_down$applicant_age, hmda_down$action_taken)
xkabledply(contable4, title="Contingency table for Loan Approval and Age")
chitest4 = chisq.test(contable4)
chitest4
```


#Building the logit model"
Changing action_taken to factor for logit/recode 1 as denial and 0 as approval because we want to calculate the probability of denial

```{r}
hmda_down$action_taken<-dplyr::recode(hmda_down$action_taken, "3"="1", "1"="0")
unique(hmda_down$action_taken)
hmda_down$action_taken<-factor(hmda_down$action_taken)
str(hmda_down)
myvars <- names(hmda_down) %in% c("approval") # dropping approval since we don't need this variable anymore
newdata <- hmda_down[!myvars]
hmda_down<-newdata
str(hmda_down)
```

### Logit models for action_taken (version with recoded approval/denial)

```{r}
###using all the variables of interest first
approval_logit <- glm(action_taken ~ derived_race + derived_ethnicity + derived_sex + loan_amount+applicant_age+ income+interest_rate+property_value, data = hmda_down, family = "binomial")
summary(approval_logit)
xkablevif(approval_logit) #check for multicollinearity
unique(hmda_down$action_taken)
```


```{r McFadden_direct}
approvalNullLogit <- glm(action_taken ~ 1, data = hmda_down, family = "binomial")
mcFadden = 1 - logLik(approval_logit)/logLik(approvalNullLogit)
mcFadden
```


#### Hosmer and Lemeshow test  

The Hosmer and Lemeshow Goodness of Fit test can be used to evaluate logistic regression fit. 

```{r HosmerLemeshow}
loadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
approveLogitHoslem = hoslem.test(hmda_down$action_taken, fitted(approval_logit)) # Hosmer and Lemeshow test, a chi-squared tests
unloadPkg("ResourceSelection") 
approveLogitHoslem
```

Per Hosmer and Leshow, our model is quite poor; p-value is extremely low
```{r HosmerLemeshowRes, results='markup', collapse=F}
approveLogitHoslem
```

```{r roc_auc}
loadPkg("pROC") 
prob=predict(approval_logit, type = "response" )
hmda_down$prob=prob
h <- roc(action_taken~prob, data=hmda_down)
auc(h) # area-under-curve prefer 0.8 or higher.
plot(h)
# unloadPkg("pROC")
```


###Feature Selection for Logit#####
```{r}
library(bestglm)
str(hmda_down)
fs_hmda_down<-hmda_down
fs_hmda_down$y = hmda_down[,4] 
str(fs_hmda_down)
fs_hmda_down<-fs_hmda_down[c(1:3, 5:9, 11)] #subset for feature selection model that does not include action_taken
str(fs_hmda_down)
res.bestglm <- bestglm(Xy = fs_hmda_down, family = binomial,
            IC = "AIC",                 # Information criteria for
            method = "exhaustive")
summary(res.bestglm)
res.bestglm$BestModels
summary(res.bestglm$BestModels)
#https://rstudio-pubs-static.s3.amazonaws.com/2897_9220b21cfc0c43a396ff9abf122bb351.html
```
#Feature selection shows that the lowest AIC would use all variables, but not certain this is true; trying the second best without the derived sex
```{r, include=TRUE}
approval_logit1 <- glm(action_taken ~ derived_race + derived_ethnicity + loan_amount+applicant_age+ income+interest_rate+property_value, data = hmda_down, family = "binomial")
summary(approval_logit1)
xkablevif(approval_logit) #check for multicollinearity
unique(hmda_down$action_taken)
```

#McFadden isn't much improved
```{r McFadden_direct 2}
approvalNullLogit <- glm(action_taken ~ 1, data = hmda_down, family = "binomial")
mcFadden = 1 - logLik(approval_logit1)/logLik(approvalNullLogit)
mcFadden
```
#Area under curve is slightly worse than in first:0.777

```{r roc_auc 2}
loadPkg("pROC") 
prob=predict(approval_logit1, type = "response" )
hmda_down$prob=prob
h <- roc(action_taken~prob, data=hmda_down)
auc(h) # area-under-curve prefer 0.8 or higher.
plot(h)
# unloadPkg("pROC")
```

#Try standardizing the data?
```{r, include=TRUE}
std_hmda_down<-hmda_down
std_hmda_down$loan_amount<-hmda_down$loan_amount/1000
std_hmda_down$property_value<-hmda_down$property_value/1000
approval_std <- glm(action_taken ~ derived_race + derived_ethnicity + loan_amount+applicant_age+ income+property_value, data = std_hmda_down, family = "binomial")
summary(approval_std)  #### took the interest rate out too
xkablevif(approval_std) #check for multicollinearity
```




#Sampling down: drawing a random sample


```{r Splitting Model for Train and Test}
set.seed(123)
index <- sample(nrow(hmda_down),nrow(hmda_down)*0.80)
training = hmda_down[index,]
testing = hmda_down[-index,]
hmda_glm0 <- glm(action_taken ~ derived_race + derived_ethnicity + derived_sex + loan_amount+applicant_age+ income+interest_rate+property_value, data = training, family = "binomial")
summary(hmda_glm0)
```
```{r verifying training and testing data}
summary(training) 
summary(testing) 
```






#Note that feature selection gives us this model below, which has the lowest deviance and lowest AIC score at 519.4.

glm(formula = action_taken ~ derived_sex + loan_amount + income + 
    property_value, family = "binomial", data = training)
    

```{r variable/feature selection using backward selection AIC}
hmda_glm_back <- step(hmda_glm0) #backward selections
summary(hmda_glm_back)
hmda_glm_back$deviance
AIC(hmda_glm_back)
```




Accuracy Score is 72% and recall rate is 73%
```{r Predictive Analysis & Confusion Matrix}
library(caret)
glm_fit = glm(action_taken ~ derived_race + derived_ethnicity + loan_amount+applicant_age+ income+interest_rate+property_value, data = training, family = "binomial")

glm_probs = data.frame(probs = predict(glm_fit, 
                                       newdata = testing, 
                                       type="response"))

glm_pred = glm_probs %>%
  mutate(pred = ifelse(probs>.5, "1", "0"))



pc<-factor(glm_pred$pred)
e<- (testing$action_taken)


table(pc)
table(e)


confusionMatrix(data=pc, reference = e)


x<-data.frame("target"=c(1,0,1,0), "prediction"=c(1,1,0,0), "n"=c(817,306,288,786))

library(ggplot2)

ggplot(x, aes(x = target, y = prediction, fill = n)) +
  geom_tile(color = "black") +
  geom_text(aes(label = n), color = "Yellow", size = 4) +
  coord_fixed()+
  scale_fill_gradient2(low = "#075AFF",
                       mid = "#FFFFCC",
                       high = "Purple") +
     scale_y_continuous(trans = "reverse", breaks = unique(x$prediction))

 



```

# decision trees 
```{r}
library(rpart)
library(rpart.plot)
fit <- rpart(action_taken~derived_sex + loan_amount + income + 
    property_value, data = training, method = 'class')
rpart.plot(fit, extra = 106)
```
At the top(node1), it is the overall probability of loan approval. It shows the proportion of applicant that get approval for their loan. 50 percent of applicant get approval.
Node1 asks whether the loan amount is equal or greater than 130e+3. If yes, then we go down to the root’s left income node (depth 2). 31 percent of applicants need loan amount over 130e+3 with loan denied probability of 64 percent.
In the node2, asking if the applicant's income is above 84. If no, 28 percent of applicant's income is below 84 and the chance of denial is 54 percent.
Asking if the applicant's loan amount is above less than 370e+3, 21 percent of applicants need loan amount over 370e+3 and the chance of denial for them is 50 percent. with loan amount below 370e+3, their chance of get denial is 67%.
13 percent of applicants's income below 60, and their loan denial chance is 56%.

#making a prediction
```{r}
predict_unseen <-predict(fit, testing, type = 'class')
```
#Create a table to count how many applicants are classified as approval and denied
```{r}
table_mat <- table(testing$action_taken, predict_unseen )
table_mat
```
#Measure performance:confustion martrix 
```{r}
accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)#0.655
```
We have a score of 66 percent for the test set.

